{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import scipy.stats as stats\n",
    "import operator\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data (Please run the cell and enter the input file path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          make fuel-type aspiration doors        style drive engine  \\\n",
      "0  alfa-romero       gas        std   two  convertible   rwd  front   \n",
      "1  alfa-romero       gas        std   two  convertible   rwd  front   \n",
      "2  alfa-romero       gas        std   two    hatchback   rwd  front   \n",
      "3         audi       gas        std  four        sedan   fwd  front   \n",
      "4         audi       gas        std  four        sedan   4wd  front   \n",
      "\n",
      "   wheel-base  length  width  ...    curb-weight  engine-size  bore  stroke  \\\n",
      "0        88.6   168.8   64.1  ...           2548          130  3.47    2.68   \n",
      "1        88.6   168.8   64.1  ...           2548          130  3.47    2.68   \n",
      "2        94.5   171.2   65.5  ...           2823          152  2.68    3.47   \n",
      "3        99.8   176.6   66.2  ...           2337          109  3.19    3.40   \n",
      "4        99.4   176.6   66.4  ...           2824          136  3.19    3.40   \n",
      "\n",
      "   compression-ratio  horsepower  peak-rpm  city-mpg  highway-mpg  price  \n",
      "0                9.0         111      5000        21           27  13495  \n",
      "1                9.0         111      5000        21           27  16500  \n",
      "2                9.0         154      5000        19           26  16500  \n",
      "3               10.0         102      5500        24           30  13950  \n",
      "4                8.0         115      5500        18           22  17450  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#Reading the data\n",
    "train_df = pd.read_csv(\"/Users/vigneshsureshbabu/Desktop/imports-85.csv\")\n",
    "n = 1000#number of rows from the dataframe\n",
    "train_data_points = 800 # number of training data points\n",
    "#deleting the column 'id' from the dataframe as it is a unique and does not have any effect on the algorithm\n",
    "\n",
    "print (train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperating the Categorical and Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating 2 seperate dataframes for categorical and continuous features.\n",
    "train_df_cat = pd.DataFrame()#training data frame with categorical features\n",
    "train_df_cont = pd.DataFrame() #training data with continuous features\n",
    "cat_list = []#list of categorical features\n",
    "cont_list = []#list of continuous features\n",
    "\n",
    "#populating the created data frames for categorical and continuous features\n",
    "cat_list = [\"make\",\"fuel-type\",\"aspiration\",\"doors\",\"style\",\"drive\",\"engine\"]\n",
    "cont_list = list(set (train_df.columns) - set (cat_list))\n",
    "\n",
    "for i in range(0,len(cat_list)):\n",
    "    train_df_cat[i] = train_df[cat_list[i]]\n",
    "train_df_cat.columns =cat_list\n",
    "for i in range(0,len(cont_list)):\n",
    "    train_df_cont[i] = train_df[cont_list[i]]\n",
    "train_df_cont.columns =cont_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binarizing the continuous Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   price  height  wheel-base  highway-mpg  stroke  compression-ratio  \\\n",
      "0  13495    48.8        88.6           27    2.68                9.0   \n",
      "1  16500    48.8        88.6           27    2.68                9.0   \n",
      "2  16500    52.4        94.5           26    3.47                9.0   \n",
      "3  13950    54.3        99.8           30    3.40               10.0   \n",
      "4  17450    54.3        99.4           22    3.40                8.0   \n",
      "\n",
      "   curb-weight  horsepower  peak-rpm  engine-size  length  width  bore  \\\n",
      "0         2548         111      5000          130   168.8   64.1  3.47   \n",
      "1         2548         111      5000          130   168.8   64.1  3.47   \n",
      "2         2823         154      5000          152   171.2   65.5  2.68   \n",
      "3         2337         102      5500          109   176.6   66.2  3.19   \n",
      "4         2824         115      5500          136   176.6   66.4  3.19   \n",
      "\n",
      "   city-mpg  \n",
      "0        21  \n",
      "1        21  \n",
      "2        19  \n",
      "3        24  \n",
      "4        18  \n",
      "(198, 14)\n"
     ]
    }
   ],
   "source": [
    "#print (train_df_cat.head())\n",
    "print (train_df_cont.head())\n",
    "print (train_df_cont.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please do not run this cell more than once, it will binarize the already binarized attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Binarization:\n",
      "   make_alfa-romero  make_audi  make_bmw  make_chevrolet  make_dodge  \\\n",
      "0                 1          0         0               0           0   \n",
      "1                 1          0         0               0           0   \n",
      "2                 1          0         0               0           0   \n",
      "3                 0          1         0               0           0   \n",
      "4                 0          1         0               0           0   \n",
      "\n",
      "   make_honda  make_isuzu  make_jaguar  make_mazda  make_mercedes-benz  \\\n",
      "0           0           0            0           0                   0   \n",
      "1           0           0            0           0                   0   \n",
      "2           0           0            0           0                   0   \n",
      "3           0           0            0           0                   0   \n",
      "4           0           0            0           0                   0   \n",
      "\n",
      "      ...       style_convertible  style_hardtop  style_hatchback  \\\n",
      "0     ...                       1              0                0   \n",
      "1     ...                       1              0                0   \n",
      "2     ...                       0              0                1   \n",
      "3     ...                       0              0                0   \n",
      "4     ...                       0              0                0   \n",
      "\n",
      "   style_sedan  style_wagon  drive_4wd  drive_fwd  drive_rwd  engine_front  \\\n",
      "0            0            0          0          0          1             1   \n",
      "1            0            0          0          0          1             1   \n",
      "2            0            0          0          0          1             1   \n",
      "3            1            0          0          1          0             1   \n",
      "4            1            0          1          0          0             1   \n",
      "\n",
      "   engine_rear  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "\n",
      "[5 rows x 38 columns]\n",
      "(198, 38)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#df_mod_onehotencoded will be the pre processed complete data including test and train\n",
    "train_df_cat = pd.get_dummies(train_df_cat)\n",
    "train_df_cat = train_df_cat.astype(int)\n",
    "\n",
    "\n",
    "print (\"After Binarization:\")\n",
    "print (train_df_cat.head())\n",
    "print (train_df_cat.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 52)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "complete_df = pd.DataFrame()\n",
    "for each_column in train_df_cat.columns:\n",
    "    complete_df[each_column] = train_df_cat[each_column]\n",
    "for each_column in train_df_cont.columns:\n",
    "    complete_df[each_column] = train_df_cont[each_column]\n",
    "print (complete_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now that we have binarized the data using the one hot encoding, we have the data in the required format\n",
    "#The next step is to apply feature selection and the machine learning algorithm\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#getting the target column into a seperate dataframe\n",
    "target_df = pd.DataFrame()\n",
    "target_df ['price'] = complete_df['price']\n",
    "#Hence deleting the target column from the features data frame\n",
    "del complete_df['price']\n",
    "#splitting tha training data and testing data\n",
    "# use train/test split with different random_state values\n",
    "x_train, x_test, y_train, y_test = train_test_split(complete_df, target_df, random_state=10)\n",
    "#print (x_train.shape)\n",
    "#print (y_train.shape)\n",
    "#print (x_test.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using 10 Fold Cross Valid with the above Combination for Tuning Depth in Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse for depth 1 is  -23401583.992826466\n",
      "The rmse for depth 2 is  -12454534.623283688\n",
      "The rmse for depth 3 is  -12454534.623283688\n",
      "The rmse for depth 4 is  -9661476.937701674\n",
      "The rmse for depth 5 is  -8896693.900742471\n",
      "The rmse for depth 6 is  -8896693.900742471\n",
      "The rmse for depth 7 is  -8896693.900742471\n",
      "The rmse for depth 8 is  -8896693.900742471\n",
      "The rmse for depth 9 is  -8896693.900742471\n",
      "The rmse for depth 10 is  -8287949.76188132\n",
      "The rmse for depth 11 is  -8287949.76188132\n",
      "The rmse for depth 12 is  -8287949.76188132\n",
      "The rmse for depth 13 is  -8287949.76188132\n",
      "The rmse for depth 14 is  -8287949.76188132\n",
      "The rmse for depth 15 is  -8287949.76188132\n",
      "The rmse for depth 16 is  -8287949.76188132\n",
      "The rmse for depth 17 is  -8287949.76188132\n",
      "The rmse for depth 18 is  -8287949.76188132\n",
      "The rmse for depth 19 is  -8287949.76188132\n",
      "The rmse for depth 20 is  -8287949.76188132\n",
      "The rmse for depth 21 is  -8287949.76188132\n",
      "The rmse for depth 22 is  -8287949.76188132\n",
      "The rmse for depth 23 is  -8287949.76188132\n",
      "The rmse for depth 24 is  -8287949.76188132\n",
      "The rmse for depth 25 is  -8287949.76188132\n",
      "The rmse for depth 26 is  -8287949.76188132\n",
      "The rmse for depth 27 is  -8287949.76188132\n",
      "The rmse for depth 28 is  -8287949.76188132\n",
      "The rmse for depth 29 is  -8287949.76188132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "count = 1\n",
    "\n",
    "k_range = range(1, 30)\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    tree = DecisionTreeRegressor(max_depth=k)\n",
    "    scores = cross_val_score(tree, x_train.values, y_train['price'].values, cv=7, scoring='mean_squared_error')\n",
    "    \n",
    "    k_scores.append(scores.mean())\n",
    "    # plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "    dec_ftre_list.append(str(i))\n",
    "    print (\"The rmse for depth\",k,\"is \",max(k_scores))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning of Depth for Random Forest (RF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search, datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {\"max_depth\": [3, 5,7,9],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"n_estimators\": [10, 20, 40, 80]}\n",
    "gs = grid_search.GridSearchCV(RandomForestRegressor(), param_grid=param_grid)\n",
    "gs.fit(x_train.values, y_train['price'].values)\n",
    "rf_pred = gs.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning of Depth for RF using Apache Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search, datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#It is implmeneted by changing just this one line\n",
    "from spark_sklearn import GridSearchCV\n",
    "\n",
    "param_grid = {\"max_depth\": [3, 5,7,9],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"n_estimators\": [10, 20, 40, 80]}\n",
    "gs = grid_search.GridSearchCV(RandomForestRegressor(), param_grid=param_grid)\n",
    "gs.fit(x_train.values, y_train['price'].values)\n",
    "rf_pred = gs.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26476138.159389578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print (mean_squared_error(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning of Depth for Gradient Boosting using Apache Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search, datasets\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#It is implmeneted by changing just this one line\n",
    "from spark_sklearn import GridSearchCV\n",
    "\n",
    "param_grid = {\"max_depth\": [3, 5,7,9],\n",
    "              \"learning_rate\": [0.01,0.1,1],\n",
    "              \"n_estimators\": [10, 20, 40, 80]}\n",
    "gbm = grid_search.GridSearchCV(GradientBoostingRegressor(), param_grid=param_grid)\n",
    "gbm.fit(x_train.values, y_train['price'].values)\n",
    "gbm_pred = gs.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
